{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae195f8d",
   "metadata": {},
   "source": [
    "# Hand-Crafted Prompts Testing Playground\n",
    "This notebook is made to offer means for testing the hand-crafted prompting method on a selection of LLMs. The notebook is meant to be a plug-and-play manner, where you could set the model id and run the cells to generate results directly.\n",
    "\n",
    "## Disclaimer\n",
    "This notebook is made to recreate Plaza-Del-Arco, F., Nozza, D., & Hovy, D. (2023). Respectful or Toxic? Using Zero-Shot Learning with Language Models to Detect Hate Speech. Retrieved from https://aclanthology.org/2023.woah-1.6.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52554004",
   "metadata": {},
   "source": [
    "## Instruction Fine-Tuned Model\n",
    "In this section, we try the instruction fine-tuned models with their prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ad6a1f-421c-4983-954f-337635d80dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3673b-1813-46c9-91fc-cbe5d5eebd45",
   "metadata": {},
   "source": [
    "### Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed09a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7122b",
   "metadata": {},
   "source": [
    "### Setting the Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f622eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"Classify this text as hate or non-hate. Text:\"\n",
    "output_indicator = \"Answer:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52ceab",
   "metadata": {},
   "source": [
    "### Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea4ecba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>as a woman you shouldnt complain about cleanin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>boy dats coldtyga dwn bad for cuffin dat hoe i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dawg you ever fuck a bitch and she start to cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>the shit you hear about me might be true or it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet\n",
       "0      2  as a woman you shouldnt complain about cleanin...\n",
       "1      1  boy dats coldtyga dwn bad for cuffin dat hoe i...\n",
       "2      1  dawg you ever fuck a bitch and she start to cr...\n",
       "3      1                             she look like a tranny\n",
       "4      1  the shit you hear about me might be true or it..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/HSOL/preprocessed_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4421441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    \"0\": \"Hate Speech\",\n",
    "    \"1\": \"Offensive\",\n",
    "    \"2\": \"Non-Hate\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987dcca3",
   "metadata": {},
   "source": [
    "### Concatenate Prompt Template to Input Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d47e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_prompt_template(df_column):\n",
    "    return df_column.apply(lambda x: f\"{prompt_template} {x}. {output_indicator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae181ade-7afb-4493-b57e-34fd1c496cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input'] = concat_prompt_template(df['tweet'])\n",
    "text_data = df['input'].astype(\"str\").tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ede63a-10eb-4db0-9ff6-7d18a36b888c",
   "metadata": {},
   "source": [
    "### Tokenize and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438ca3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text_data, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb7f2f20-5ee6-49f7-bd5d-eba4d1f7648a",
   "metadata": {},
   "source": [
    "def batch_inference(data_list):\n",
    "    decoded = list()\n",
    "    for i in tqdm(range(0, len(data_list)-1000, 1000)):\n",
    "        inputs = tokenizer(data_list[i:i+1000], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        sequences = model.generate(**inputs, do_sample=True, min_length=0, max_length=10, temperature=0.001)\n",
    "        decoded.extend(tokenizer.batch_decode(sequences, skip_special_tokens=True))\n",
    "    return decoded\n",
    "decoded = batch_inference(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05a88a4-beb5-464d-a530-91e6921c6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'flan_t5_hsol_results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5994c56f-a786-4ddc-97d5-fc0d552127ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open(filename, 'w')\n",
    "for i, out in enumerate(decoded):\n",
    "    file_object.write(out)\n",
    "    file_object.write(',')\n",
    "    file_object.write(labels[str(df[\"class\"][i])])\n",
    "    file_object.write('\\n')\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee79305f-7ab9-4731-a3af-594db83634a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate None</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           output      truth\n",
       "0       Hate None  Offensive\n",
       "1  Hate None-hate  Offensive\n",
       "2        Non-hate  Offensive\n",
       "3  Hate None-hate  Offensive\n",
       "4  Hate None-hate  Offensive"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(filename)\n",
    "results.columns = [\"output\", \"truth\"]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee33db05-9ed6-4a2c-bd39-997c19181dc7",
   "metadata": {},
   "source": [
    "### Answer Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4107096e-8fc6-41bf-8669-787251337460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate None</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           output      truth\n",
       "0       Hate None  Offensive\n",
       "1  Hate None-hate  Offensive\n",
       "2        Non-hate  Offensive\n",
       "3  Hate None-hate  Offensive\n",
       "4  Hate None-hate  Offensive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'flan_t5_hsol_results.csv'\n",
    "results = pd.read_csv(filename)\n",
    "results.columns = [\"output\", \"truth\"]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a5f38-34d5-4a94-9344-de8784329313",
   "metadata": {},
   "source": [
    "### Qualitative Analysis\n",
    "First of all, we want to know how many answers were not mapped to either \"Hate\" or \"Non-Hate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c6ee78-a879-4a75-b9e1-864e6b1e8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_non_correct_outputs(series):\n",
    "    return series.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b195353-975d-493c-8691-11f60beb2226",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['isCorrect'] = results['output'].apply(lambda x: x.lower() == 'hate' or x.lower() == 'non-hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bcc5b2-b51b-456c-a9ab-24dd5814cff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>truth</th>\n",
       "      <th>isCorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hate None</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hate None-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           output      truth  isCorrect\n",
       "0       Hate None  Offensive      False\n",
       "1  Hate None-hate  Offensive      False\n",
       "2        Non-hate  Offensive       True\n",
       "3  Hate None-hate  Offensive      False\n",
       "4  Hate None-hate  Offensive      False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b337974f-15cf-457c-8cfe-f8a536ccb5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10108"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctCount = results[results.isCorrect == True]\n",
    "len(correctCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c9917-fcf5-4053-bbdf-4a8b19085aad",
   "metadata": {},
   "source": [
    "We got almost half of the samples with correct output, so we begin and map those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6ab3ec-4893-44f1-b9f8-dda6e3f9cf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>truth</th>\n",
       "      <th>isCorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      output      truth  isCorrect\n",
       "2   Non-hate  Offensive       True\n",
       "6   Non-hate  Offensive       True\n",
       "8   Non-hate  Offensive       True\n",
       "9   Non-hate  Offensive       True\n",
       "11  Non-hate  Offensive       True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctCount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e1eec-2a91-4228-b7b5-cc3013136c8f",
   "metadata": {},
   "source": [
    "Convert all offensive labels to Non-hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89183b2-c6df-4333-b644-d23ce96abe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omer\\AppData\\Local\\Temp\\ipykernel_9740\\4216773890.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  correctCount['truthModified'] = correctCount['truth'].apply(lambda x: 'Non-hate' if x.lower() == 'offensive' else x)\n"
     ]
    }
   ],
   "source": [
    "correctCount['truthModified'] = correctCount['truth'].apply(lambda x: 'Non-hate' if x.lower() == 'offensive' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "931df479-b246-4d75-a9cb-d2821fb58059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>truth</th>\n",
       "      <th>isCorrect</th>\n",
       "      <th>truthModified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Non-hate</td>\n",
       "      <td>Offensive</td>\n",
       "      <td>True</td>\n",
       "      <td>Non-hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      output      truth  isCorrect truthModified\n",
       "2   Non-hate  Offensive       True      Non-hate\n",
       "6   Non-hate  Offensive       True      Non-hate\n",
       "8   Non-hate  Offensive       True      Non-hate\n",
       "9   Non-hate  Offensive       True      Non-hate\n",
       "11  Non-hate  Offensive       True      Non-hate"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctCount.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02589dd7-7973-4918-b926-0d5a5a1befa1",
   "metadata": {},
   "source": [
    "Now we count the correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9beceb8a-a3e0-40d9-b378-c6b003f0624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omer\\AppData\\Local\\Temp\\ipykernel_9740\\221834817.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  correctCount['isCorrectAns'] = correctCount.apply(lambda x: x.output.lower() == x.truthModified.lower(), axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9648"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctCount['isCorrectAns'] = correctCount.apply(lambda x: x.output.lower() == x.truthModified.lower(), axis=1)\n",
    "correctAnsCount = len(correctCount[correctCount.isCorrectAns == True])\n",
    "correctAnsCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee98b4-257c-456f-a955-2acca8241425",
   "metadata": {},
   "source": [
    "### Mapping the answer classes to either 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80617a7b-383d-43b3-871f-3a2ca9fce14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omer\\AppData\\Local\\Temp\\ipykernel_9740\\3975601444.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  correctCount['outputLabel'] = correctCount['output'].apply(mapAnswers)\n",
      "C:\\Users\\Omer\\AppData\\Local\\Temp\\ipykernel_9740\\3975601444.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  correctCount['truthLabel'] = correctCount['truthModified'].apply(mapAnswers)\n"
     ]
    }
   ],
   "source": [
    "def mapAnswers(answer):\n",
    "    if answer.lower() == 'non-hate':\n",
    "        return 0\n",
    "    elif answer.lower() == 'hate':\n",
    "        return 1\n",
    "    else: return None\n",
    "\n",
    "correctCount['outputLabel'] = correctCount['output'].apply(mapAnswers)\n",
    "correctCount['truthLabel'] = correctCount['truthModified'].apply(mapAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33af4d51-dda0-49a7-8784-51a0b22a0872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        0.0\n",
       "6        0.0\n",
       "8        0.0\n",
       "9        0.0\n",
       "11       0.0\n",
       "        ... \n",
       "23990    0.0\n",
       "23993    0.0\n",
       "23994    0.0\n",
       "23995    0.0\n",
       "23996    0.0\n",
       "Name: truthLabel, Length: 10108, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctCount['truthLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "446a8407-9867-42ca-ac51-bb2c9ce8cac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        0\n",
       "6        0\n",
       "8        0\n",
       "9        0\n",
       "11       0\n",
       "        ..\n",
       "23990    0\n",
       "23993    0\n",
       "23994    0\n",
       "23995    0\n",
       "23996    0\n",
       "Name: outputLabel, Length: 10108, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctCount['outputLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b57769a-1ed1-4adc-8d83-8ee582653ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctCount = correctCount.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7ce7943-28ec-49f4-87b9-cdeefc12da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9648"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correctCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4c86133-1bfd-42a4-9c7b-afa9de026e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be046dc4-5416-4c9b-b970-dff5e135550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omer\\anaconda3\\envs\\dsenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "score = f1_score(correctCount['truthLabel'], correctCount['outputLabel'], labels=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3b919cc-d545-4a57-9800-81d1fd8df2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
