{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b433aa52-5286-40b4-b118-2a24ce03071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f39a829df70>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/urllib3/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f39a829d9a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/urllib3/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f39a829d190>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/urllib3/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f39a829d700>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/urllib3/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f39a829dbe0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/urllib3/\u001b[0m\n",
      "Requirement already up-to-date: urllib3 in /home/omar/.local/lib/python3.8/site-packages (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6c30c2-7af4-4a2b-9f35-069c6ab94b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q peft transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6c1ab9-25ab-433c-bc9d-4c48c8be60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Replace \"0\" with the index of the GPU you want to use\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"]= \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5301e8da-9aef-4d0d-825a-beb74f939757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PromptEncoderConfig,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "features = ['Non-Hate','Hate Speech']\n",
    "\n",
    "model_name_or_path = \"roberta-base\"\n",
    "num_epochs = 5\n",
    "lr = 1e-3\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23309380-6cbb-4fbe-ae58-abb6d35d0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset(\"glue\", task)\n",
    "# dataset[\"train\"][0]\n",
    "# {\n",
    "#     \"sentence1\": 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
    "#     \"sentence2\": 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
    "#     \"label\": 1,\n",
    "#     \"idx\": 0,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2190fdf-3da0-47ac-991e-b566fc798d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset,DatasetDict, load_dataset\n",
    "\n",
    "df = pd.read_csv('../data/MHS/mhs_preprocessed_data.csv')\n",
    "df = df.dropna()\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train = Dataset.from_pandas(train)\n",
    "test = Dataset.from_pandas(test)\n",
    "ds_dict = {'train' : train,\n",
    "           'test' : test}\n",
    "dataset = DatasetDict(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b358ba2-7145-4890-bc70-092313c3c65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07643f57b4cf45bc8728fccefdb26a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5807ab286d5943a486f7a8413facc037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda x: {\"text_label\": [features[label] for label in x[\"HS\"]]},\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66ad49c3-df13-4caa-ac66-bfe8bd4da275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'HS', '__index_level_0__', 'text_label'],\n",
       "    num_rows: 108444\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ebaa9ac-5f0d-4009-8403-83ba9b41bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/omar/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Mon Jan 15 21:28:09 2024) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6c2cc67-dd40-460f-a5f1-9419d9902481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a70356c1-0fbf-4463-b6a1-bcc59f4b01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(k in model_name_or_path for k in (\"gpt\", \"opt\", \"bloom\")):\n",
    "    padding_side = \"left\"\n",
    "else:\n",
    "    padding_side = \"right\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=padding_side)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    # print( examples)\n",
    "    outputs = tokenizer(examples[\"text\"], truncation=True, max_length=128)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a250cce-4906-4b1a-9935-3e8eba91333a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be091cb074843aa9be981e80dbe9038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deb8ee821714afb949fdeaabd24c4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\", \"text_label\", \"__index_level_0__\"],\n",
    ")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"HS\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53606525-235c-466d-86ad-95ab6ab74745",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50c561e1-c076-4481-b835-96c5db4ea329",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=20, encoder_hidden_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24ca7aa2-6199-483e-8b3a-675b181f717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 821,506 || all params: 125,468,676 || trainable%: 0.654749875578507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trainable params: 1351938 || all params: 355662082 || trainable%: 0.38011867680626127'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\"trainable params: 1351938 || all params: 355662082 || trainable%: 0.38011867680626127\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "192eeee2-bdef-42cf-9cdf-fa6fcbcca113",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"your-name/roberta-large-peft-p-tuning\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76b2dccd-432d-4b31-8381-48a3616b3228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54222' max='54222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54222/54222 45:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.356788</td>\n",
       "      <td>0.872598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.334600</td>\n",
       "      <td>0.337540</td>\n",
       "      <td>0.875696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=54222, training_loss=0.40081109128581055, metrics={'train_runtime': 2705.4781, 'train_samples_per_second': 80.166, 'train_steps_per_second': 20.042, 'total_flos': 6557946703595520.0, 'train_loss': 0.40081109128581055, 'epoch': 2.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdbe416f-970b-4f96-99b7-0698379446fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 29902, 44831,  7188,  1359,   828,  5559,     2]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes = [\"not equivalent\", \"equivalent\"]\n",
    "\n",
    "sentence1 = \"these niggers straight bitches\"\n",
    "sentence2 = \"\"\n",
    "\n",
    "inputs = tokenizer(sentence1, truncation=False, return_tensors=\"pt\")\n",
    "\n",
    "inputs.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed2db3f4-999d-488d-a903-e7695f52c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7312, -0.7071]], device='cuda:0')\n",
      "Non-Hate: 81%\n",
      "Hate Speech: 19%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'equivalent: 96%'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "    print(outputs)\n",
    "\n",
    "paraphrased_text = torch.softmax(outputs, dim=1).tolist()[0]\n",
    "for i in range(len(features)):\n",
    "    print(f\"{features[i]}: {int(round(paraphrased_text[i] * 100))}%\")\n",
    "\"not equivalent: 4%\"\n",
    "\"equivalent: 96%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5ee4b-e3c8-4196-b8f1-d767aafa1996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509ac89-91be-45cc-a568-535ee3253d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5efc6-f7ab-4f5c-9fd1-55c85e5ab414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e20600-91e7-431b-a3a2-4c9226b8d36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df2631-f00a-410d-9a8f-3fae6346478c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9cc59-f536-45b2-815b-9321f0a0a761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281152f7-783a-4b40-8229-81d08f876ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd221361-c399-4a1f-b9f5-e7899f482887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747cdb7-a934-4cc1-93e6-d7beb95aef4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293877de-7f14-4f0a-8472-000c7af3b96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235796a-cfcc-458d-82a5-63144996cf4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a4bda-6eef-4ce0-a2f0-c638c6ac8e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
