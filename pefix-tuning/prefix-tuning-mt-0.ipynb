{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7345136,"sourceType":"datasetVersion","datasetId":4265092}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# FLAN-T5 Prefix-Tuning\nThis notebook is made to prefix-tune FLAN-T5 on Hateeval.","metadata":{}},{"cell_type":"markdown","source":"### 1. Imports and Constants","metadata":{}},{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:55:53.081594Z","iopub.execute_input":"2024-01-11T07:55:53.082464Z","iopub.status.idle":"2024-01-11T07:55:55.979185Z","shell.execute_reply.started":"2024-01-11T07:55:53.082430Z","shell.execute_reply":"2024-01-11T07:55:55.978263Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:55:55.980731Z","iopub.execute_input":"2024-01-11T07:55:55.981099Z","iopub.status.idle":"2024-01-11T07:56:08.773042Z","shell.execute_reply.started":"2024-01-11T07:55:55.981075Z","shell.execute_reply":"2024-01-11T07:56:08.771806Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting peft\n  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/8b/1b/aee2a330d050c493642d59ba6af51f3910cb138ea48ede228c84c204a5af/peft-0.7.1-py3-none-any.whl.metadata\n  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.36.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.1)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.20.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.7.1-py3-none-any.whl (168 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_linear_schedule_with_warmup\nfrom peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType\nimport os\nfrom datasets import Dataset,DatasetDict, load_dataset\nfrom torch.utils.data import DataLoader\nimport torch\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Features, ClassLabel\n\nfeatures = ['Non-Hate','Hate Speech']\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n\ndevice = \"cuda\"\nmodel_name_or_path = \"bigscience/mt0-base\"\ntokenizer_name_or_path = \"bigscience/mt0-base\"\n\ntext_column = \"text\"\nlabel_column = \"text_label\"\nmax_length = 128\nlr = 1e-2\nnum_epochs = 20\nbatch_size = 8","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:08.774895Z","iopub.execute_input":"2024-01-11T07:56:08.775681Z","iopub.status.idle":"2024-01-11T07:56:22.132720Z","shell.execute_reply.started":"2024-01-11T07:56:08.775621Z","shell.execute_reply":"2024-01-11T07:56:22.131890Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 2. Loading Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hateeval/hateeval_preprocessed_data.csv')\ndf = df.dropna()\ntrain, test = train_test_split(df, test_size=0.2)\ntrain = Dataset.from_pandas(train)\ntest = Dataset.from_pandas(test)\nds_dict = {'train' : train,\n           'test' : test}\ndataset = DatasetDict(ds_dict)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:22.134753Z","iopub.execute_input":"2024-01-11T07:56:22.135309Z","iopub.status.idle":"2024-01-11T07:56:22.222640Z","shell.execute_reply.started":"2024-01-11T07:56:22.135282Z","shell.execute_reply":"2024-01-11T07:56:22.221924Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### 3. Preprocessing Data\nInitialize a tokenizer, and create a function to pad and truncate the model_inputs and labels:","metadata":{}},{"cell_type":"code","source":"dataset = dataset.map(\n    lambda x: {\"text_label\": [features[label] for label in x[\"HS\"]]},\n    batched=True,\n    num_proc=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:22.223721Z","iopub.execute_input":"2024-01-11T07:56:22.224012Z","iopub.status.idle":"2024-01-11T07:56:22.341356Z","shell.execute_reply.started":"2024-01-11T07:56:22.223987Z","shell.execute_reply":"2024-01-11T07:56:22.340511Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6288df235164817a9bddc96cc42c6d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"605f812444fd4752bda11a7b0bea0764"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\n\ndef preprocess_function(examples):\n    inputs = examples[text_column]\n    targets = examples[label_column]\n    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    model_inputs['input_ids'] = model_inputs['input_ids'].reshape(max_length)\n    labels = tokenizer(targets, max_length=5, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    labels = labels[\"input_ids\"]\n    labels[labels == tokenizer.pad_token_id] = -100\n    model_inputs[\"labels\"] = labels.reshape(5)\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:22.342450Z","iopub.execute_input":"2024-01-11T07:56:22.342728Z","iopub.status.idle":"2024-01-11T07:56:24.835390Z","shell.execute_reply.started":"2024-01-11T07:56:22.342704Z","shell.execute_reply":"2024-01-11T07:56:24.834613Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/430 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00da4c3f2095456fb79188d89bbb7be7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d376dc8b1e41eeb56e16f118a06829"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b139dd39069f4229ba442e287c926c22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a2dccdda3cd475eacd9c894a3a949d3"}},"metadata":{}}]},{"cell_type":"markdown","source":"Use the map function to apply the preprocess_function to the dataset. You can remove the unprocessed columns since the model doesn’t need them anymore:","metadata":{}},{"cell_type":"code","source":"processed_datasets = dataset.map(\n    preprocess_function,\n    num_proc=1,\n    remove_columns=dataset[\"train\"].column_names,\n    load_from_cache_file=False,\n    desc=\"Running tokenizer on dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:24.836638Z","iopub.execute_input":"2024-01-11T07:56:24.837005Z","iopub.status.idle":"2024-01-11T07:56:32.221368Z","shell.execute_reply.started":"2024-01-11T07:56:24.836963Z","shell.execute_reply":"2024-01-11T07:56:32.220620Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/7982 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"793a038b65a34ac08e14ea5162e7763c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/1996 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9445efcd12419a936a7c386aa63c0e"}},"metadata":{}}]},{"cell_type":"markdown","source":"Create a DataLoader from the train and eval datasets. Set pin_memory=True to speed up the data transfer to the GPU during training if the samples in your dataset are on a CPU.","metadata":{}},{"cell_type":"code","source":"train_dataset = processed_datasets[\"train\"]\neval_dataset = processed_datasets[\"test\"]\ntrain_dataloader = DataLoader(\n    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n)\neval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:32.222528Z","iopub.execute_input":"2024-01-11T07:56:32.222979Z","iopub.status.idle":"2024-01-11T07:56:32.228736Z","shell.execute_reply.started":"2024-01-11T07:56:32.222946Z","shell.execute_reply":"2024-01-11T07:56:32.227782Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### 4. Train model\nNow you can setup your model and make sure it is ready for training. Specify the task in PrefixTuningConfig, create the base t5-large model from AutoModelForSeq2SeqLM, and then wrap the model and configuration in a PeftModel. Feel free to print the PeftModel’s parameters and compare it to fully training all the model parameters to see how much more efficient it is!","metadata":{}},{"cell_type":"code","source":"peft_config = PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, num_virtual_tokens=20)\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:32.230124Z","iopub.execute_input":"2024-01-11T07:56:32.230769Z","iopub.status.idle":"2024-01-11T07:56:46.707828Z","shell.execute_reply.started":"2024-01-11T07:56:32.230736Z","shell.execute_reply":"2024-01-11T07:56:46.706849Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/798 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b039ed4c22746f99c872f09d2c03207"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57a70f1b78e5423aadd48ec5f8ab8e4b"}},"metadata":{}},{"name":"stdout","text":"trainable params: 368,640 || all params: 582,769,920 || trainable%: 0.06325652497644353\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Setup the optimizer and learning rate scheduler:\r\n","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=(len(train_dataloader) * num_epochs),\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:46.711266Z","iopub.execute_input":"2024-01-11T07:56:46.711538Z","iopub.status.idle":"2024-01-11T07:56:46.718458Z","shell.execute_reply.started":"2024-01-11T07:56:46.711515Z","shell.execute_reply":"2024-01-11T07:56:46.717639Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Move the model to the GPU, and then write a training loop to begin!\r\n","metadata":{}},{"cell_type":"code","source":"model = model.to(device)\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for step, batch in enumerate(tqdm(train_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        total_loss += loss.detach().float()\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n\n    model.eval()\n    eval_loss = 0\n    eval_preds = []\n    for step, batch in enumerate(tqdm(eval_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        loss = outputs.loss\n        eval_loss += loss.detach().float()\n        eval_preds.extend(\n            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n        )\n\n    eval_epoch_loss = eval_loss / len(eval_dataloader)\n    eval_ppl = torch.exp(eval_epoch_loss)\n    train_epoch_loss = total_loss / len(train_dataloader)\n    train_ppl = torch.exp(train_epoch_loss)\n    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-11T07:56:46.719616Z","iopub.execute_input":"2024-01-11T07:56:46.719885Z","iopub.status.idle":"2024-01-11T08:24:41.381544Z","shell.execute_reply.started":"2024-01-11T07:56:46.719862Z","shell.execute_reply":"2024-01-11T08:24:41.380590Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77025b6087764738b7b6d2fa9f1a7209"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c5a486f2ea4782b1388b657f247157"}},"metadata":{}},{"name":"stdout","text":"epoch=0: train_ppl=tensor(1.3858, device='cuda:0') train_epoch_loss=tensor(0.3263, device='cuda:0') eval_ppl=tensor(1.1358, device='cuda:0') eval_epoch_loss=tensor(0.1273, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4c29262a5724de785845a14976bb3dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5fc35f9febe4f09a00823d034d104b1"}},"metadata":{}},{"name":"stdout","text":"epoch=1: train_ppl=tensor(1.1508, device='cuda:0') train_epoch_loss=tensor(0.1405, device='cuda:0') eval_ppl=tensor(1.1232, device='cuda:0') eval_epoch_loss=tensor(0.1162, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11be208e867f4c2d817a5b72a3ac9d83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbcffa824b854dec93151efaf8d0187a"}},"metadata":{}},{"name":"stdout","text":"epoch=2: train_ppl=tensor(1.1427, device='cuda:0') train_epoch_loss=tensor(0.1334, device='cuda:0') eval_ppl=tensor(1.1184, device='cuda:0') eval_epoch_loss=tensor(0.1119, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d847e9c94cbd46c09f901d68906be571"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"248818700a3e4ef6af7b863d9be7f0da"}},"metadata":{}},{"name":"stdout","text":"epoch=3: train_ppl=tensor(1.1339, device='cuda:0') train_epoch_loss=tensor(0.1257, device='cuda:0') eval_ppl=tensor(1.1155, device='cuda:0') eval_epoch_loss=tensor(0.1093, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abf9f3f42c3e41ac89b8fa3a0dc79423"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32fa66564a7c40a48191d4b1e4523d99"}},"metadata":{}},{"name":"stdout","text":"epoch=4: train_ppl=tensor(1.1285, device='cuda:0') train_epoch_loss=tensor(0.1209, device='cuda:0') eval_ppl=tensor(1.1169, device='cuda:0') eval_epoch_loss=tensor(0.1106, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed057e2c5c754016bb0316dd33645b6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb2df68e4e734742b71819e6cc74a66e"}},"metadata":{}},{"name":"stdout","text":"epoch=5: train_ppl=tensor(1.1276, device='cuda:0') train_epoch_loss=tensor(0.1201, device='cuda:0') eval_ppl=tensor(1.1190, device='cuda:0') eval_epoch_loss=tensor(0.1124, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01f2c80a7c01483c8d3898b66bd90830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a293c49da11f49ef91309ea94a214c1f"}},"metadata":{}},{"name":"stdout","text":"epoch=6: train_ppl=tensor(1.1267, device='cuda:0') train_epoch_loss=tensor(0.1193, device='cuda:0') eval_ppl=tensor(1.1081, device='cuda:0') eval_epoch_loss=tensor(0.1026, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b18ab074a62c4ac790f2f2a5471bd66f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e245f3090b884d74bd7211c0d9755d77"}},"metadata":{}},{"name":"stdout","text":"epoch=7: train_ppl=tensor(1.1235, device='cuda:0') train_epoch_loss=tensor(0.1165, device='cuda:0') eval_ppl=tensor(1.1104, device='cuda:0') eval_epoch_loss=tensor(0.1047, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"345de1c66c7b4bb79676d7ad338b1aa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51de962206004441bf7058a06cfd518f"}},"metadata":{}},{"name":"stdout","text":"epoch=8: train_ppl=tensor(1.1222, device='cuda:0') train_epoch_loss=tensor(0.1153, device='cuda:0') eval_ppl=tensor(1.1049, device='cuda:0') eval_epoch_loss=tensor(0.0997, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9364f849924457595e70c8dc438e862"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f55f47d7598a4247a9decdc0e0666df8"}},"metadata":{}},{"name":"stdout","text":"epoch=9: train_ppl=tensor(1.1197, device='cuda:0') train_epoch_loss=tensor(0.1130, device='cuda:0') eval_ppl=tensor(1.1043, device='cuda:0') eval_epoch_loss=tensor(0.0992, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0610b6a5e4a349938145153d93177d10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8a84718afec4ed88633532158d1d2ca"}},"metadata":{}},{"name":"stdout","text":"epoch=10: train_ppl=tensor(1.1197, device='cuda:0') train_epoch_loss=tensor(0.1130, device='cuda:0') eval_ppl=tensor(1.1032, device='cuda:0') eval_epoch_loss=tensor(0.0982, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d5788f498d459891e4eb4cd51efd65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4e8097a0c4842338fca9ed25d09d41c"}},"metadata":{}},{"name":"stdout","text":"epoch=11: train_ppl=tensor(1.1180, device='cuda:0') train_epoch_loss=tensor(0.1115, device='cuda:0') eval_ppl=tensor(1.1065, device='cuda:0') eval_epoch_loss=tensor(0.1012, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9af5f23471f247c4940e746a45489228"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbf3c343ba744c509c349b3ae958b6c8"}},"metadata":{}},{"name":"stdout","text":"epoch=12: train_ppl=tensor(1.1169, device='cuda:0') train_epoch_loss=tensor(0.1106, device='cuda:0') eval_ppl=tensor(1.1015, device='cuda:0') eval_epoch_loss=tensor(0.0967, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1732d79167a0428a966e49b48f22f4f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f757180cfe5a416f8bc02a6c60614ec0"}},"metadata":{}},{"name":"stdout","text":"epoch=13: train_ppl=tensor(1.1157, device='cuda:0') train_epoch_loss=tensor(0.1095, device='cuda:0') eval_ppl=tensor(1.1076, device='cuda:0') eval_epoch_loss=tensor(0.1022, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3419b4374e714d33a1412407407da3dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9b91b6dc17d45cfb225b9edcc99cc4c"}},"metadata":{}},{"name":"stdout","text":"epoch=14: train_ppl=tensor(1.1141, device='cuda:0') train_epoch_loss=tensor(0.1080, device='cuda:0') eval_ppl=tensor(1.1040, device='cuda:0') eval_epoch_loss=tensor(0.0989, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a68a327ac784a0fb05c58573081209a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0eb1bc47f0d491da38cd10232be5bbc"}},"metadata":{}},{"name":"stdout","text":"epoch=15: train_ppl=tensor(1.1132, device='cuda:0') train_epoch_loss=tensor(0.1073, device='cuda:0') eval_ppl=tensor(1.1021, device='cuda:0') eval_epoch_loss=tensor(0.0973, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9c3cb76cf4f433886cdc0711c334d84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ae96d86ef8049c2aa54bdbefb0fad2c"}},"metadata":{}},{"name":"stdout","text":"epoch=16: train_ppl=tensor(1.1140, device='cuda:0') train_epoch_loss=tensor(0.1080, device='cuda:0') eval_ppl=tensor(1.1011, device='cuda:0') eval_epoch_loss=tensor(0.0963, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebaedfde728a4a5597885cc335d6f669"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd072101da74ac8a55a234c3ddb0eb4"}},"metadata":{}},{"name":"stdout","text":"epoch=17: train_ppl=tensor(1.1149, device='cuda:0') train_epoch_loss=tensor(0.1087, device='cuda:0') eval_ppl=tensor(1.1002, device='cuda:0') eval_epoch_loss=tensor(0.0955, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ba952b5542d4b2795ddc0e93e0a5f19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf578912c54494ab9573edc7bb22e0e"}},"metadata":{}},{"name":"stdout","text":"epoch=18: train_ppl=tensor(1.1112, device='cuda:0') train_epoch_loss=tensor(0.1054, device='cuda:0') eval_ppl=tensor(1.1012, device='cuda:0') eval_epoch_loss=tensor(0.0964, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"926f552565564275bfdd1afeae26e192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df0177d7d844da686c7bb3754ee2ec1"}},"metadata":{}},{"name":"stdout","text":"epoch=19: train_ppl=tensor(1.1113, device='cuda:0') train_epoch_loss=tensor(0.1055, device='cuda:0') eval_ppl=tensor(1.1003, device='cuda:0') eval_epoch_loss=tensor(0.0956, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let’s see how well the model performs on the validation set:\r\n","metadata":{}},{"cell_type":"code","source":"correct = 0\ntotal = 0\nfor pred, true in zip(eval_preds, dataset[\"test\"][\"text_label\"]):\n    if pred.strip() == true.strip():\n        correct += 1\n    total += 1\naccuracy = correct / total * 100\nprint(f\"{accuracy=} % on the evaluation dataset\")\nprint(f\"{eval_preds[:10]=}\")\nprint(f\"{dataset['test']['text_label'][:10]=}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-11T08:24:41.382889Z","iopub.execute_input":"2024-01-11T08:24:41.383195Z","iopub.status.idle":"2024-01-11T08:24:41.395998Z","shell.execute_reply.started":"2024-01-11T08:24:41.383169Z","shell.execute_reply":"2024-01-11T08:24:41.394997Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"accuracy=76.60320641282566 % on the evaluation dataset\neval_preds[:10]=['Hate Speech', 'Non-Hate', 'Hate Speech', 'None Speech', 'Non-Hate', 'Hate Speech', 'Non-Hate', 'Non-Hate', 'Hate Speech', 'Hate Speech']\ndataset['test']['text_label'][:10]=['Hate Speech', 'Non-Hate', 'Hate Speech', 'Hate Speech', 'Non-Hate', 'Hate Speech', 'Non-Hate', 'Non-Hate', 'Hate Speech', 'Hate Speech']\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-01-11T08:24:41.397326Z","iopub.execute_input":"2024-01-11T08:24:41.397969Z","iopub.status.idle":"2024-01-11T08:24:41.428226Z","shell.execute_reply.started":"2024-01-11T08:24:41.397935Z","shell.execute_reply":"2024-01-11T08:24:41.427336Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbbf4f11a62348f28641d0cca49bb61f"}},"metadata":{}}]},{"cell_type":"code","source":"peft_model_id = \"omarxadel/mt0-base-hs-prefix-tuning\"\nmodel.push_to_hub(peft_model_id, use_auth_token=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-11T08:26:53.401937Z","iopub.execute_input":"2024-01-11T08:26:53.402291Z","iopub.status.idle":"2024-01-11T08:26:54.678036Z","shell.execute_reply.started":"2024-01-11T08:26:53.402265Z","shell.execute_reply":"2024-01-11T08:26:54.677131Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/1.47M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4187e46b1c41bcb093309e9c343bf2"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/omarxadel/mt0-base-hs-prefix-tuning/commit/86f9b0823d0e59907f9651c75e00e98a3ace0f20', commit_message='Upload model', commit_description='', oid='86f9b0823d0e59907f9651c75e00e98a3ace0f20', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]}]}