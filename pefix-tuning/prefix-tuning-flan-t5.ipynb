{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7345136,"sourceType":"datasetVersion","datasetId":4265092}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# FLAN-T5 Prefix-Tuning\nThis notebook is made to prefix-tune FLAN-T5 on Hateeval.","metadata":{}},{"cell_type":"markdown","source":"### 1. Imports and Constants","metadata":{}},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:56:49.096103Z","iopub.execute_input":"2024-01-06T22:56:49.096847Z","iopub.status.idle":"2024-01-06T22:57:03.015721Z","shell.execute_reply.started":"2024-01-06T22:56:49.096812Z","shell.execute_reply":"2024-01-06T22:57:03.014283Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting peft\n  Obtaining dependency information for peft from https://files.pythonhosted.org/packages/8b/1b/aee2a330d050c493642d59ba6af51f3910cb138ea48ede228c84c204a5af/peft-0.7.1-py3-none-any.whl.metadata\n  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.36.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.25.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.1)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.7.1-py3-none-any.whl (168 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_linear_schedule_with_warmup\nfrom peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType\nimport os\nfrom datasets import Dataset,DatasetDict, load_dataset\nfrom torch.utils.data import DataLoader\nimport torch\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Features, ClassLabel\n\nfeatures = ['Non-Hate','Hate']\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n\ndevice = \"cuda\"\nmodel_name_or_path = \"google/flan-t5-xl\"\ntokenizer_name_or_path = \"google/flan-t5-xl\"\n\ntext_column = \"text\"\nlabel_column = \"text_label\"\nmax_length = 128\nmin_length = 0\nlr = 1e-2\nnum_epochs = 5\nbatch_size = 8","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:03.018094Z","iopub.execute_input":"2024-01-06T22:57:03.018405Z","iopub.status.idle":"2024-01-06T22:57:17.819217Z","shell.execute_reply.started":"2024-01-06T22:57:03.018378Z","shell.execute_reply":"2024-01-06T22:57:17.818360Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 2. Loading Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hateeval/hateeval_preprocessed_data.csv')\ndf = df.dropna()\ntrain, test = train_test_split(df, test_size=0.2)\ntrain = Dataset.from_pandas(train)\ntest = Dataset.from_pandas(test)\nds_dict = {'train' : train,\n           'test' : test}\ndataset = DatasetDict(ds_dict)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:17.820408Z","iopub.execute_input":"2024-01-06T22:57:17.821030Z","iopub.status.idle":"2024-01-06T22:57:17.909850Z","shell.execute_reply.started":"2024-01-06T22:57:17.821000Z","shell.execute_reply":"2024-01-06T22:57:17.908841Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### 3. Preprocessing Data\nInitialize a tokenizer, and create a function to pad and truncate the model_inputs and labels:","metadata":{}},{"cell_type":"code","source":"dataset = dataset.map(\n    lambda x: {\"text_label\": [features[label] for label in x[\"HS\"]]},\n    batched=True,\n    num_proc=1,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:17.914489Z","iopub.execute_input":"2024-01-06T22:57:17.914779Z","iopub.status.idle":"2024-01-06T22:57:18.090539Z","shell.execute_reply.started":"2024-01-06T22:57:17.914755Z","shell.execute_reply":"2024-01-06T22:57:18.089494Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"602b6310d77b42c5b19e4a23177f2605"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"360deb13e48540f295b45507bbb6b28b"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n\n\ndef preprocess_function(examples):\n    inputs = examples[text_column]\n    targets = examples[label_column]\n    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    model_inputs['input_ids'] = model_inputs['input_ids'].reshape(128)\n    labels = tokenizer(targets, max_length=10, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    labels = labels[\"input_ids\"]\n    labels[labels == tokenizer.pad_token_id] = -100\n    model_inputs[\"labels\"] = labels.reshape(10)\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:18.091742Z","iopub.execute_input":"2024-01-06T22:57:18.092032Z","iopub.status.idle":"2024-01-06T22:57:19.164269Z","shell.execute_reply.started":"2024-01-06T22:57:18.092005Z","shell.execute_reply":"2024-01-06T22:57:19.163315Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5259e0e458e44fc9902b33a4cd888028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd2241305ce847068b69375235e5aeef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e047ee82b9bc446585317f86ddf9bef0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f47a1ac133146dd82169a2ca51e7d03"}},"metadata":{}}]},{"cell_type":"markdown","source":"Use the map function to apply the preprocess_function to the dataset. You can remove the unprocessed columns since the model doesn’t need them anymore:","metadata":{}},{"cell_type":"code","source":"processed_datasets = dataset.map(\n    preprocess_function,\n    num_proc=1,\n    remove_columns=dataset[\"train\"].column_names,\n    load_from_cache_file=False,\n    desc=\"Running tokenizer on dataset\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:19.165477Z","iopub.execute_input":"2024-01-06T22:57:19.165826Z","iopub.status.idle":"2024-01-06T22:57:26.354250Z","shell.execute_reply.started":"2024-01-06T22:57:19.165793Z","shell.execute_reply":"2024-01-06T22:57:26.353472Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/7982 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5edf1ee048304522aa4c0687fc862555"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on dataset:   0%|          | 0/1996 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"992d566e83f2467c82d7702aa49634e5"}},"metadata":{}}]},{"cell_type":"markdown","source":"Create a DataLoader from the train and eval datasets. Set pin_memory=True to speed up the data transfer to the GPU during training if the samples in your dataset are on a CPU.","metadata":{}},{"cell_type":"code","source":"train_dataset = processed_datasets[\"train\"]\neval_dataset = processed_datasets[\"test\"]\ntrain_dataloader = DataLoader(\n    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n)\neval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:26.355598Z","iopub.execute_input":"2024-01-06T22:57:26.356311Z","iopub.status.idle":"2024-01-06T22:57:26.362486Z","shell.execute_reply.started":"2024-01-06T22:57:26.356274Z","shell.execute_reply":"2024-01-06T22:57:26.361478Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### 4. Train model\nNow you can setup your model and make sure it is ready for training. Specify the task in PrefixTuningConfig, create the base t5-large model from AutoModelForSeq2SeqLM, and then wrap the model and configuration in a PeftModel. Feel free to print the PeftModel’s parameters and compare it to fully training all the model parameters to see how much more efficient it is!","metadata":{}},{"cell_type":"code","source":"print(batch_size)\n\nfor step, batch in enumerate(tqdm(train_dataloader)):\n#     batch = {k: v.to(device) for k, v in batch.items()}\n    input_shape = batch['input_ids'].size()\n    batch_size, seq_length = input_shape\n    print(batch_size, seq_length)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:26.363818Z","iopub.execute_input":"2024-01-06T22:57:26.364223Z","iopub.status.idle":"2024-01-06T22:57:26.578896Z","shell.execute_reply.started":"2024-01-06T22:57:26.364188Z","shell.execute_reply":"2024-01-06T22:57:26.578009Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"904ac3f38cc140e6a47175e44168282f"}},"metadata":{}},{"name":"stdout","text":"8 128\n","output_type":"stream"}]},{"cell_type":"code","source":"peft_config = PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, num_virtual_tokens=20)\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\nmodel = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:57:26.580305Z","iopub.execute_input":"2024-01-06T22:57:26.580619Z","iopub.status.idle":"2024-01-06T22:58:36.166451Z","shell.execute_reply.started":"2024-01-06T22:57:26.580594Z","shell.execute_reply":"2024-01-06T22:58:36.165231Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae4e58d7814e4f339f214daf29d997fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a3ae83cfa64291b1e5d7f4873c0e26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"464ff0299b484c898ec886df21d25345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aec0252642af4a73b4b8482b8666f3cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bd3f28c2e8243bd9d937e820b57d4ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0914d76d71a42b7ad2abc30663fd3de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0952d61436284b618ac759def4e2d7cd"}},"metadata":{}},{"name":"stdout","text":"trainable params: 1,966,080 || all params: 2,851,723,264 || trainable%: 0.06894357614638445\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Setup the optimizer and learning rate scheduler:\r\n","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=(len(train_dataloader) * num_epochs),\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:58:36.170434Z","iopub.execute_input":"2024-01-06T22:58:36.171166Z","iopub.status.idle":"2024-01-06T22:58:36.184574Z","shell.execute_reply.started":"2024-01-06T22:58:36.171122Z","shell.execute_reply":"2024-01-06T22:58:36.183373Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Move the model to the GPU, and then write a training loop to begin!\r\n","metadata":{}},{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:58:36.185795Z","iopub.execute_input":"2024-01-06T22:58:36.186132Z","iopub.status.idle":"2024-01-06T22:58:39.883639Z","shell.execute_reply.started":"2024-01-06T22:58:36.186105Z","shell.execute_reply":"2024-01-06T22:58:39.882351Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(device)\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for step, batch in enumerate(tqdm(train_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        total_loss += loss.detach().float()\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n\n    model.eval()\n    eval_loss = 0\n    eval_preds = []\n    for step, batch in enumerate(tqdm(eval_dataloader)):\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        loss = outputs.loss\n        eval_loss += loss.detach().float()\n        eval_preds.extend(\n            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n        )\n\n    eval_epoch_loss = eval_loss / len(eval_dataloader)\n    eval_ppl = torch.exp(eval_epoch_loss)\n    train_epoch_loss = total_loss / len(train_dataloader)\n    train_ppl = torch.exp(train_epoch_loss)\n    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-06T22:58:39.885080Z","iopub.execute_input":"2024-01-06T22:58:39.885776Z","iopub.status.idle":"2024-01-07T00:49:07.329259Z","shell.execute_reply.started":"2024-01-06T22:58:39.885746Z","shell.execute_reply":"2024-01-07T00:49:07.328431Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c34355740641289641a5f1d3d51380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2ba99f3ced04a5fa2969aa38b523776"}},"metadata":{}},{"name":"stdout","text":"epoch=0: train_ppl=tensor(1.2291, device='cuda:0') train_epoch_loss=tensor(0.2063, device='cuda:0') eval_ppl=tensor(1.1329, device='cuda:0') eval_epoch_loss=tensor(0.1247, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0591941c3f4457a86486eb5e562e01b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f26ed98bd32549fd89717728f003208a"}},"metadata":{}},{"name":"stdout","text":"epoch=1: train_ppl=tensor(1.1454, device='cuda:0') train_epoch_loss=tensor(0.1357, device='cuda:0') eval_ppl=tensor(1.1465, device='cuda:0') eval_epoch_loss=tensor(0.1367, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6272fdfdd0f140e1a91ba91160407806"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ffd7c73280b40529a0551e33939d4f3"}},"metadata":{}},{"name":"stdout","text":"epoch=2: train_ppl=tensor(1.1287, device='cuda:0') train_epoch_loss=tensor(0.1211, device='cuda:0') eval_ppl=tensor(1.1066, device='cuda:0') eval_epoch_loss=tensor(0.1013, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d74599f45fb54f3889c834cbbc8a41bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e82d32c32d14302935950cec3571b22"}},"metadata":{}},{"name":"stdout","text":"epoch=3: train_ppl=tensor(1.1195, device='cuda:0') train_epoch_loss=tensor(0.1129, device='cuda:0') eval_ppl=tensor(1.1127, device='cuda:0') eval_epoch_loss=tensor(0.1068, device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/998 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58e822ee68084a789a3d197b191ec353"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ab2edbef3444905bc41d2b68fcab871"}},"metadata":{}},{"name":"stdout","text":"epoch=4: train_ppl=tensor(1.1139, device='cuda:0') train_epoch_loss=tensor(0.1079, device='cuda:0') eval_ppl=tensor(1.1053, device='cuda:0') eval_epoch_loss=tensor(0.1001, device='cuda:0')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let’s see how well the model performs on the validation set:\r\n","metadata":{}},{"cell_type":"code","source":"correct = 0\ntotal = 0\nfor pred, true in zip(eval_preds, dataset[\"test\"][\"text_label\"]):\n    if pred.strip() == true.strip():\n        correct += 1\n    total += 1\naccuracy = correct / total * 100\nprint(f\"{accuracy=} % on the evaluation dataset\")\nprint(f\"{eval_preds[:10]=}\")\nprint(f\"{dataset['test']['text_label'][:10]=}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:49:54.655891Z","iopub.execute_input":"2024-01-07T00:49:54.656729Z","iopub.status.idle":"2024-01-07T00:49:54.670099Z","shell.execute_reply.started":"2024-01-07T00:49:54.656693Z","shell.execute_reply":"2024-01-07T00:49:54.669179Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"accuracy=0.0501002004008016 % on the evaluation dataset\neval_preds[:10]=['Non-Hate Hat Hat Non ', 'Hate Hat Hat Hat Hat Hat Hat Hat', 'Non-Hate Non Immigration Immigration Immigration', 'Hate Hat Hat Hat Hat Hat Hat Hat', 'Non-Hate Hat Hat Hat Non', 'Hat-Hate Hat Hat Hat Hat Hat', 'Hate Hat Hat Hat Hat Hat Hat ', 'Hate Hat Hat Hat Hat Hat Hat Hat', 'Hate Hat Hat Hat Hat Hat Hat Hat', 'Hate Hat Hat Hat Hat Hat Hat Hat']\ndataset['test']['text_label'][:10]=['Non-Hate', 'Hate', 'Non-Hate', 'Hate', 'Non-Hate', 'Non-Hate', 'Hate', 'Hate', 'Hate', 'Hate']\n","output_type":"stream"}]}]}